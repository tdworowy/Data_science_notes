{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last validation result : 0.949000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from scipy.sparse import csr_matrix\n",
    "news_groups_dataset = fetch_20newsgroups(shuffle=True, remove=('headers','footers','quotes'), random_state=6)\n",
    "def streaming():\n",
    "    for response, item in zip(news_groups_dataset.target, news_groups_dataset.data):\n",
    "        yield response, item\n",
    "hashing_trick = HashingVectorizer(stop_words='english', norm='l2', non_negative=True )\n",
    "learner = SGDClassifier(random_state=101)\n",
    "texts = list()\n",
    "targets = list()\n",
    "for n,(target, text) in enumerate(streaming()):\n",
    "    texts.append(text)\n",
    "    targets.append(target)\n",
    "    if n % 1000 == 0 and n > 0:\n",
    "        learning_chunk = hashing_trick.transform(texts)\n",
    "        learner.partial_fit(learning_chunk, targets, classes=[k for k in range(20)])\n",
    "        if n > 1000:\n",
    "            last_validation_score = learner.score(learning_chunk, targets)\n",
    "        texts, targets = list(), list()\n",
    "print (\"Last validation result : %f\" % last_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted discussion group rec.autos\n"
     ]
    }
   ],
   "source": [
    "new_text = ['A 2014 red Toyota Prius v Five with fewer than 14k miles. Powered by\\\n",
    "            a reliable 1.8L four cylinder hybrid engin taht averges 44mpg\\\n",
    "            in the city and 40mpg on the higway.']\n",
    "text_vector = hashing_trick.transform(new_text)\n",
    "index = learner.predict(text_vector)\n",
    "print(\"Predicted discussion group %s\" % news_groups_dataset.target_names[int(index)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
